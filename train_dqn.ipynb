{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a0efc9",
   "metadata": {},
   "source": [
    "1. Import dependencies + Create required directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e954e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import GrayscaleObservation, ResizeObservation, FrameStackObservation\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa523de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_dir = os.path.join('training', 'logs')\n",
    "save_dir = os.path.join('training', 'saved_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55402db6",
   "metadata": {},
   "source": [
    "2. Create CarRacing-v3 Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a0e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_ID = \"CarRacing-v3\"\n",
    "\n",
    "def make_env(render_mode=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        render_mode: Default to None, render_mode=\"human\" to visualize the driving\n",
    "    Output:\n",
    "        env (the created CarRacing-v3 environment) with modifications: greyscaled, and scaled down\n",
    "            (to reduce computation load)\n",
    "    \"\"\"\n",
    "    env = gym.make(ENV_ID, continuous=False, render_mode=render_mode)\n",
    "    env = GreyscaleObservation(env)\n",
    "    env = ResizeObservation(env, (84, 84))\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bf95a",
   "metadata": {},
   "source": [
    "3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29b4e038",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GreyscaleObservation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_env = \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m train_env = VecFrameStack(train_env, n_stack=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\.conda\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:31\u001b[39m, in \u001b[36mDummyVecEnv.__init__\u001b[39m\u001b[34m(self, env_fns)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym.Env]]):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28mself\u001b[39m.envs = \u001b[43m[\u001b[49m\u001b[43m_patch_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_fns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env.unwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.envs])) != \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.envs):\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     34\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minstead of creating different objects. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\.conda\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:31\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym.Env]]):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28mself\u001b[39m.envs = [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env.unwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.envs])) != \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.envs):\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     34\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minstead of creating different objects. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m         )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_env = DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m])\n\u001b[32m      2\u001b[39m train_env = VecFrameStack(train_env, n_stack=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mmake_env\u001b[39m\u001b[34m(render_mode)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mInput:\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    render_mode: Default to None, render_mode=\"human\" to visualize the driving\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33;03m        (to reduce computation load)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m env = gym.make(ENV_ID, continuous=\u001b[38;5;28;01mFalse\u001b[39;00m, render_mode=render_mode)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m env = \u001b[43mGreyscaleObservation\u001b[49m(env)\n\u001b[32m     13\u001b[39m env = ResizeObservation(env, (\u001b[32m84\u001b[39m, \u001b[32m84\u001b[39m))\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "\u001b[31mNameError\u001b[39m: name 'GreyscaleObservation' is not defined"
     ]
    }
   ],
   "source": [
    "train_env = DummyVecEnv([lambda: make_env(render_mode=None)])\n",
    "train_env = VecFrameStack(train_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = DummyVecEnv([lambda: make_env(render_mode=None)])\n",
    "eval_env = VecFrameStack(eval_env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ed1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure our DQN model with parameters\n",
    "model = DQN(\n",
    "    policy='CnnPolicy', \n",
    "    env=train_env, \n",
    "    learning_rate=1e-4, \n",
    "    buffer_size=100_000,\n",
    "    learning_starts=10_000,\n",
    "    batch_size=128,\n",
    "    train_freq=4,\n",
    "    target_update_interval=1_000,\n",
    "    gamma=0.99,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.1,\n",
    "    exploration_fraction=0.5,\n",
    "    tensorboard_log=log_path,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval callback\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=os.path.join('training', 'best_model'),\n",
    "    log_path=os.path.join('training', 'best_model_logs'),\n",
    "    eval_freq=10_000,\n",
    "    n_eval_episodes=5,\n",
    "    deterministic=True,\n",
    "    render=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model.learn(total_timesteps=200_000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aada35",
   "metadata": {},
   "source": [
    "4. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join(save_dir, \"dqn_carracing\")\n",
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9115c2",
   "metadata": {},
   "source": [
    "5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec75011",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(\"training\", \"best_model\", \"best_model.zip\")\n",
    "best_model = DQN.load(best_model_path)\n",
    "\n",
    "mean_r, std_r = evaluate_policy(best_model, eval_env, n_eval_episodes=10, render=True)\n",
    "print(f\"Best Model:\\nMean Reward: {mean_r:.2f}\\tStandard Deviation: {std_r:.2f}\")\n",
    "\n",
    "eval_env.close()\n",
    "train_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
